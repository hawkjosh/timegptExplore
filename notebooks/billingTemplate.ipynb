{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from nixtlats import TimeGPT\n",
    "from IPython.display import Markdown\n",
    "\n",
    "currDir = os.getcwd()\n",
    "os.chdir(\"../data\")\n",
    "from dataUtils import generateQuery, movePlusRename, dataPrep  # noqa: E402\n",
    "\n",
    "os.chdir(\"../usage\")\n",
    "from usageUtils import getUsage  # noqa: E402\n",
    "\n",
    "os.chdir(currDir)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Kusto query to get sample data set from Azure Data Explorer\n",
    "\n",
    "# TODO: add tenantId param\n",
    "\n",
    "tenantId = \"\"\n",
    "daysAgo = 180\n",
    "\n",
    "generateQuery(tenantId=tenantId, daysAgo=daysAgo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Manually pasting the query (copied to clipboard using pyperclip) into ADE, running, and exporting result to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input params for sample billing data and run data prep function. The function movePlusRename moves and renames the ADE query export file to this project directory and returns the new file name.\n",
    "\n",
    "# TODO: add new name of ADE query export file\n",
    "\n",
    "df = \"df\"\n",
    "filename = movePlusRename(name=\"\")\n",
    "timeCol = \"TimePeriod\"\n",
    "dropCols = [\"Tenant\"]\n",
    "\n",
    "bd180 = dataPrep(df=df, filename=filename, timeCol=timeCol, dropCols=dropCols)\n",
    "\n",
    "display(bd180.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt = TimeGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current API token usage data\n",
    "\n",
    "getUsage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection model, plot results compared with original data (default prediction interval level is 99)\n",
    "\n",
    "bd180Dtct = timegpt.detect_anomalies(\n",
    "    bd180, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\"\n",
    ")\n",
    "\n",
    "bd180Anms = bd180Dtct[bd180Dtct[\"anomaly\"] == 1]\n",
    "\n",
    "bd180Plt = timegpt.plot(\n",
    "    bd180, bd180Dtct, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"### Anomalies Detection Result (Default 99% Prediction Interval Level)\"),\n",
    "    bd180Dtct,\n",
    "    Markdown(\"### Detected Anomalies (Default 99% Prediction Interval Level)\"),\n",
    "    bd180Anms,\n",
    "    Markdown(\"### Results Comparison Plot (Default 99% Prediction Interval Level)\"),\n",
    "    bd180Plt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical prediction intervals to test against detected anomalies\n",
    "\n",
    "bd180Fcst = timegpt.forecast(\n",
    "    bd180, h=1, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\", add_history=True, level=[99, 90, 99.99],\n",
    ")\n",
    "\n",
    "bd180Fcst = bd180Fcst.merge(bd180)\n",
    "\n",
    "for lv in [99, 90, 99.99]:\n",
    "    bd180Fcst[f\"anomaly_{lv}\"] = (\n",
    "        bd180Fcst[\"ProratedQuantity\"] > bd180Fcst[f\"TimeGPT-hi-{lv}\"]\n",
    "    ) | (\n",
    "        bd180Fcst[\"ProratedQuantity\"] < bd180Fcst[f\"TimeGPT-lo-{lv}\"]\n",
    "    )\n",
    "\n",
    "    bd180Fcst[f\"anomaly_{lv}\"] = bd180Fcst[f\"anomaly_{lv}\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detected anomalies against historical prediction intervals defalut level 99\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    bd180Fcst[\"anomaly_99\"],\n",
    "    bd180Dtct.merge(bd180)[\"anomaly\"],\n",
    "    check_index=False,\n",
    "    check_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection model, plot results compared with original data (prediction interval level 90 should identify more anomalies)\n",
    "\n",
    "bd180Dtct90 = timegpt.detect_anomalies(\n",
    "    bd180, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\", level=90\n",
    ")\n",
    "\n",
    "bd180Anms90 = bd180Dtct90[bd180Dtct90[\"anomaly\"] == 1]\n",
    "\n",
    "bd180Plt90 = timegpt.plot(\n",
    "    bd180, bd180Dtct90, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"### Anomalies Detection Result (90% Prediction Interval Level)\"),\n",
    "    bd180Dtct90,\n",
    "    Markdown(\"### Detected Anomalies (90% Prediction Interval Level)\"),\n",
    "    bd180Anms90,\n",
    "    Markdown(\"### Results Comparison Plot (90% Prediction Interval Level)\"),\n",
    "    bd180Plt90,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detected anomalies against historical prediction interval level 90\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    bd180Fcst[\"anomaly_90\"],\n",
    "    bd180Dtct90.merge(bd180)[\"anomaly\"],\n",
    "    check_index=False,\n",
    "    check_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection model, plot results compared with original data (prediction interval level 99.99 should identify fewer anomalies)\n",
    "\n",
    "bd180Dtct99_99 = timegpt.detect_anomalies(\n",
    "    bd180, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\", level=99.99,\n",
    ")\n",
    "\n",
    "bd180Anms99_99 = bd180Dtct99_99[bd180Dtct99_99[\"anomaly\"] == 1]\n",
    "\n",
    "bd180Plt99_99 = timegpt.plot(\n",
    "    bd180, bd180Dtct99_99, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"### Anomalies Detection Result (99.99% Prediction Interval Level)\"),\n",
    "    bd180Dtct99_99,\n",
    "    Markdown(\"### Detected Anomalies (99.99% Prediction Interval Level)\"),\n",
    "    bd180Anms99_99,\n",
    "    Markdown(\"### Results Comparison Plot (99.99% Prediction Interval Level)\"),\n",
    "    bd180Plt99_99,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detected anomalies against historical prediction interval level 99.99\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    bd180Fcst[\"anomaly_99.99\"],\n",
    "    bd180Dtct99_99.merge(bd180)[\"anomaly\"],\n",
    "    check_index=False,\n",
    "    check_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get updated API token usage data\n",
    "\n",
    "getUsage(update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Kusto query to get sample data set from Azure Data Explorer\n",
    "\n",
    "# TODO: add tenantId param\n",
    "\n",
    "tenantId = \"\"\n",
    "daysAgo = 90\n",
    "\n",
    "generateQuery(tenantId=tenantId, daysAgo=daysAgo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Manually pasting the query (copied to clipboard using pyperclip) into ADE, running, and exporting result to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input params for sample billing data and run data prep function. The function movePlusRename moves and renames the ADE query export file to this project directory and returns the new file name.\n",
    "\n",
    "# TODO: add new name of ADE query export file\n",
    "\n",
    "df = \"df\"\n",
    "filename = movePlusRename(name=\"\")\n",
    "timeCol = \"TimePeriod\"\n",
    "dropCols = [\"Tenant\"]\n",
    "\n",
    "bd90 = dataPrep(df=df, filename=filename, timeCol=timeCol, dropCols=dropCols)\n",
    "\n",
    "display(bd90.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection model, plot results compared with original data (default prediction interval level is 99)\n",
    "\n",
    "bd90Dtct = timegpt.detect_anomalies(\n",
    "    bd90, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\"\n",
    ")\n",
    "\n",
    "bd90Anms = bd90Dtct[bd90Dtct[\"anomaly\"] == 1]\n",
    "\n",
    "bd90Plt = timegpt.plot(\n",
    "    bd90, bd90Dtct, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"### Anomalies Detection Result (Default 99% Prediction Interval Level)\"),\n",
    "    bd90Dtct,\n",
    "    Markdown(\"### Detected Anomalies (Default 99% Prediction Interval Level)\"),\n",
    "    bd90Anms,\n",
    "    Markdown(\"### Results Comparison Plot (Default 99% Prediction Interval Level)\"),\n",
    "    bd90Plt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical prediction intervals to test against detected anomalies\n",
    "\n",
    "bd90Fcst = timegpt.forecast(\n",
    "    bd90, h=1, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\", add_history=True, level=[99, 90, 99.99],\n",
    ")\n",
    "\n",
    "bd90Fcst = bd90Fcst.merge(bd90)\n",
    "\n",
    "for lv in [99, 90, 99.99]:\n",
    "    bd90Fcst[f\"anomaly_{lv}\"] = (\n",
    "        bd90Fcst[\"ProratedQuantity\"] > bd90Fcst[f\"TimeGPT-hi-{lv}\"]\n",
    "    ) | (\n",
    "        bd90Fcst[\"ProratedQuantity\"] < bd90Fcst[f\"TimeGPT-lo-{lv}\"]\n",
    "    )\n",
    "\n",
    "    bd90Fcst[f\"anomaly_{lv}\"] = bd90Fcst[f\"anomaly_{lv}\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detected anomalies against historical prediction intervals defalut level 99\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    bd90Fcst[\"anomaly_99\"],\n",
    "    bd90Dtct.merge(bd90)[\"anomaly\"],\n",
    "    check_index=False,\n",
    "    check_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection model, plot results compared with original data (prediction interval level 90 should identify more anomalies)\n",
    "\n",
    "bd90Dtct90 = timegpt.detect_anomalies(\n",
    "    bd90, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\", level=90\n",
    ")\n",
    "\n",
    "bd90Anms90 = bd90Dtct90[bd90Dtct90[\"anomaly\"] == 1]\n",
    "\n",
    "bd90Plt90 = timegpt.plot(\n",
    "    bd90, bd90Dtct90, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"### Anomalies Detection Result (90% Prediction Interval Level)\"),\n",
    "    bd90Dtct90,\n",
    "    Markdown(\"### Detected Anomalies (90% Prediction Interval Level)\"),\n",
    "    bd90Anms90,\n",
    "    Markdown(\"### Results Comparison Plot (90% Prediction Interval Level)\"),\n",
    "    bd90Plt90,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detected anomalies against historical prediction interval level 90\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    bd90Fcst[\"anomaly_90\"],\n",
    "    bd90Dtct90.merge(bd90)[\"anomaly\"],\n",
    "    check_index=False,\n",
    "    check_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection model, plot results compared with original data (prediction interval level 99.99 should identify fewer anomalies)\n",
    "\n",
    "bd90Dtct99_99 = timegpt.detect_anomalies(\n",
    "    bd90, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\", freq=\"D\", level=99.99,\n",
    ")\n",
    "\n",
    "bd90Anms99_99 = bd90Dtct99_99[bd90Dtct99_99[\"anomaly\"] == 1]\n",
    "\n",
    "bd90Plt99_99 = timegpt.plot(\n",
    "    bd90, bd90Dtct99_99, time_col=\"TimePeriod\", target_col=\"ProratedQuantity\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"### Anomalies Detection Result (99.99% Prediction Interval Level)\"),\n",
    "    bd90Dtct99_99,\n",
    "    Markdown(\"### Detected Anomalies (99.99% Prediction Interval Level)\"),\n",
    "    bd90Anms99_99,\n",
    "    Markdown(\"### Results Comparison Plot (99.99% Prediction Interval Level)\"),\n",
    "    bd90Plt99_99,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detected anomalies against historical prediction interval level 99.99\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    bd90Fcst[\"anomaly_99.99\"],\n",
    "    bd90Dtct99_99.merge(bd90)[\"anomaly\"],\n",
    "    check_index=False,\n",
    "    check_names=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
